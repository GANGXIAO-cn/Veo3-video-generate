import os
import time
import asyncio
from dotenv import load_dotenv
from typing import Annotated, TypedDict

from utils import (
    get_client,
    ainvoke_llm_async,
    get_current_date,
    start_video_generation,
    wait_for_completion,
    get_video_url
)
from db_utils import log_to_db, init_db
from prompt_library import PROMPT_LIBRARY


# âœ… ç±»å‹çº¦æŸï¼ˆç”¨äºè§£æç»“æ„åŒ– LLM è¾“å‡ºï¼‰
class VideoDetails(TypedDict):
    title: str
    prompt: str

import json
from typing import TypedDict

# å®šä¹‰è¿”å›çš„ VideoDetails ç±»å‹
class VideoDetails(TypedDict):
    title: str
    prompt: str

 
import json
async def generate_veo3_video_prompt(client, ad_idea: str, prompt: str) -> VideoDetails:
    print(f"ğŸ§  Generating prompt for idea: '{ad_idea}'")
    
    system_prompt = """
    You are a helpful assistant. Given a creative ad idea and an inspiration prompt,
    return a structured JSON object with:
    - title: title of the video
    - prompt: visual and stylistic prompt used for video generation

    Respond ONLY in this format:
    {
      "title": "...",
      "prompt": "..."
    }
    """
    
    user_message = f"Ad Idea: {ad_idea}\n\nInspiration Prompt:\n{prompt}"

    try:
        # è°ƒç”¨ LLM å¼‚æ­¥ç”Ÿæˆæç¤ºè¯
        # ainvoke_llm_async ç°åœ¨ç›´æ¥è¿”å›ä¸€ä¸ªè§£æå¥½çš„å­—å…¸
        result_dict = await ainvoke_llm_async(
            client=client,
            model="gemini-2.5-flash", # ä½ æ—¥å¿—ä¸­ç”¨çš„æ˜¯ gemini-2.5-flash
            system_prompt=system_prompt,
            user_message=user_message,
            temperature=0.3,
            response_format=VideoDetails
        )
        
        # æ£€æŸ¥å“åº”å†…å®¹ (è¿™æ˜¯å¾ˆå¥½çš„è°ƒè¯•ä¹ æƒ¯)
        if isinstance(result_dict, dict) and 'title' in result_dict:
            print(f"LLM è°ƒç”¨å®Œæˆï¼ŒæˆåŠŸè§£æå“åº”å†…å®¹ï¼š{json.dumps(result_dict, indent=2, ensure_ascii=False)}")
            # ç›´æ¥è¿”å›æˆåŠŸè§£æåçš„å­—å…¸
            return result_dict
        else:
            # å¦‚æœè¿”å›çš„ä¸æ˜¯é¢„æœŸçš„å­—å…¸æ ¼å¼ï¼Œåˆ™æŠ›å‡ºé”™è¯¯
            print(f"âŒ LLM è¿”å›äº†éé¢„æœŸçš„æ ¼å¼: {result_dict}")
            raise ValueError("LLM did not return the expected dictionary format.")

    except Exception as e:
        # æ•è·æ¥è‡ª ainvoke_llm_async çš„å¼‚å¸¸æˆ–æœ¬å‡½æ•°å†…çš„å¼‚å¸¸
        print(f"âŒ åœ¨æç¤ºè¯ç”Ÿæˆæµç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        # è¿”å›ä¸€ä¸ªç»Ÿä¸€çš„é”™è¯¯æ ¼å¼
        return {"error": "Prompt generation failed", "message": str(e)}

async def run_workflow(inputs):
    log_entry = {
        "title": "",
        "prompt": "",
        "status": "in_progress",
        "created_at": get_current_date(),
        "video_url": None,
        "error": None,
    }

    row_id = None

    try:
        api_key = inputs.get("key")
        if not api_key:
            raise ValueError("âŒ API Key is required")

        client = get_client(api_key)

        print(f"ğŸš€ å¼€å§‹è¿è¡Œ workflowï¼Œè¾“å…¥å‚æ•°ä¸º: {inputs}")

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæç¤ºè¯
        try:
            video_details = await generate_veo3_video_prompt(
                client,
                inputs["ad_idea"],
                inputs["prompt"]
            )
            log_entry["title"] = video_details["title"]
            log_entry["prompt"] = video_details["prompt"]
        except Exception as e:
            log_entry["status"] = "failed"
            log_entry["error"] = f"ğŸ§  Prompt generation failed: {str(e)}"
            row_id = log_to_db(log_entry)
            return {"error": log_entry["error"]}

        row_id = log_to_db(log_entry)
        print(f"ğŸ“˜ Prompt ç”ŸæˆæˆåŠŸï¼ŒLog ID: {row_id}")

        # ç¬¬äºŒæ­¥ï¼šå¯åŠ¨è§†é¢‘ä»»åŠ¡
        try:
            task = start_video_generation(client, video_details["prompt"])
            log_entry["task_id"] = task.name
        except Exception as e:
            log_entry["status"] = "failed"
            log_entry["error"] = f"ğŸ¬ Video generation task failed: {str(e)}"
            log_to_db(log_entry, row_id)
            return {"error": log_entry["error"]}

        log_to_db(log_entry, row_id)
        print(f"ğŸ¬ ä»»åŠ¡å¯åŠ¨æˆåŠŸ: {task.name}")

        # ç¬¬ä¸‰æ­¥ï¼šè½®è¯¢ç»“æœ
        try:
            result = wait_for_completion(client, task)
        except Exception as e:
            log_entry["status"] = "failed"
            log_entry["error"] = f"â³ Polling failed: {str(e)}"
            log_to_db(log_entry, row_id)
            return {"error": log_entry["error"]}

        # ç¬¬å››æ­¥ï¼šè§£æè§†é¢‘ URL
        try:
            video_url = get_video_url(result)
            log_entry["status"] = "completed"
            log_entry["video_url"] = video_url
            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_url}")
        except Exception as e:
            log_entry["status"] = "failed"
            log_entry["error"] = f"ğŸ“¥ Failed to extract video URL: {str(e)}"
            print(log_entry["error"])

        # æœ€åå†™å…¥ DB å¹¶è¿”å›
        log_to_db(log_entry, row_id)

        if log_entry["status"] == "completed":
            return {
                "title": log_entry["title"],
                "prompt": log_entry["prompt"],
                "video_url": log_entry["video_url"]
            }
        else:
            return {"error": log_entry["error"]}

    except Exception as e:
        # å¤–éƒ¨æ„å¤–é”™è¯¯ä¹Ÿè®°å½•
        if row_id:
            log_entry["status"] = "failed"
            log_entry["error"] = f"ğŸ”¥ Unexpected error: {str(e)}"
            log_to_db(log_entry, row_id)
        print(f"ğŸ”¥ run_workflow è‡´å‘½é”™è¯¯: {str(e)}")
        return {"error": str(e)}


if __name__ == "__main__":
    load_dotenv()
    init_db()

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("âŒ GEMINI_API_KEY environment variable not set")

    ad_idea = "I want an ad for the launch of the new Mercedes Formula 1 car"
    prompt = PROMPT_LIBRARY[-1]["prompt"]

    inputs = {
        "ad_idea": ad_idea,
        "prompt": prompt,
        "key": api_key
    }

    asyncio.run(run_workflow(inputs))
